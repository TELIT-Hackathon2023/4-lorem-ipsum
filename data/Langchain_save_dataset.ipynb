{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-26T06:25:27.167337200Z",
     "start_time": "2023-11-26T06:25:16.870582800Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from typing import Iterable\n",
    "\n",
    "def load_docs_from_jsonl(file_path)->Iterable[Document]:\n",
    "    array = []\n",
    "    with open(file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            data = json.loads(line)\n",
    "            obj = Document(**data)\n",
    "            array.append(obj)\n",
    "    return array\n",
    "\n",
    "\n",
    "documents = load_docs_from_jsonl(\"./docs/data_web_complete.jsonl\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T06:25:27.206371Z",
     "start_time": "2023-11-26T06:25:27.169389100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(docs, embeddings, persist_directory=\"./chroma_db_extended\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T06:57:04.142111300Z",
     "start_time": "2023-11-26T06:25:27.201267900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='Like Aragorn, Frodo Baggins also presents a differing version of the book-character, who is the nephew and pupil of Bilbo Baggins, and is hobbit-gentry, wealthy and educated, schooled in Elvish lore and all-round adventuring. He is described by Gandalf as \"a stout little fellow with red cheeks, taller than some, fairer than most,\" and \"a perky chap with a bright eye,\" and showing a fondness for', metadata={'source': 'http://lotr.fandom.com/wiki/Tolkien vs. Jackson: Differences Between Story and Screenplay'})]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k=1 because we only want one result\n",
    "db.similarity_search(\"who is frodo?\", k=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T06:57:15.798984300Z",
     "start_time": "2023-11-26T06:57:15.510977400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = db.as_retriever()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "# Connect to GPT-3.5 turbo\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Use temperature=0 to get the same results every time\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"who is frodo?\"\n",
    "chain.invoke(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
